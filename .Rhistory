oma = c(2,4,1,1))
for (xxx in 1:10){
# Select distance data (for bars of histogram per observer)
sp <- d[which(d$Species == s_good[xxx]), which(colnames(d) %in% c("Year", "Banda", "transectID", "T_Y", "Species", "Observer", "Cluster", "Temp", "distance"))] # Select species spAL and all years
ob <- unique(sp$Observer)
# Load model (for different sigma mean per observer)
setwd("S:/PhD/Second chapter/Data/Results/TRIM/6temp")
load(paste("HDS_",s_good[xxx],".RData", sep = ""))
sum <- out$summary
sigmas <- sum[grep("sig.obs", rownames(sum)), 1] # Sigmas are the log of the sigmas in reality?
exp.sig <- exp(sigmas) # Back transform to obtain sigma in the natural scale?????
curve(g(x, sig=exp.sig[1]), 0, 200, xlab="Distance (x)", ylab=s_good[xxx], lwd = 2, frame = F, col = c[1], ylim = c(0,1))
mtext("Detection probability", side = 2, line = 3, cex = 0.7)
for (i in 2:length(ob)){ # For each species
curve(g(x, sig=exp.sig[i]), 0, 200, add=TRUE, lwd = 2, col = c[i])
}
}
mtext("Distance (m)", side = 1, line = 1, cex = 0.8, outer = TRUE)
mtext("Detection probability", side = 2, line = 1, cex = 0.8, outer = TRUE)
xxx = 1
s_good <- c("ALRUF","BUOED","CACAR","COOEN","COPAL","GACRI","GATHE","MEAPI","MECAL","PAMAJ","SESER","STSSP","SYCAN","SYMEL","TERAX","UPEPO",
"MICAL","HIRUS","PADOM","PIPIC","PAMON", "COMON")
s_good <- sort(s_good)
# Select distance data (for bars of histogram per observer)
sp <- d[which(d$Species == s_good[xxx]), which(colnames(d) %in% c("Year", "Banda", "transectID", "T_Y", "Species", "Observer", "Cluster", "Temp", "distance"))] # Select species spAL and all years
ob <- unique(sp$Observer)
# Load model (for different sigma mean per observer)
setwd("S:/PhD/Second chapter/Data/Results/TRIM/6temp")
load(paste("HDS_",s_good[xxx],".RData", sep = ""))
setwd("S:/PhD/Second chapter/Data")
d <- read.csv("DataDS_ready_ALL.csv")
colnames(d)[which(colnames(d) == "Count")] <- "Cluster"
s_good <- c("MICAL", "PADOM", "MEAPI", "TERAX")
c <- palette(rainbow(15))
# 2. Define detection function
g <- function(x, sig) exp(-x^2/(2*sig^2))
x <- runif(40, 0, 200)
setwd("S:/PhD/Second chapter/Data/Results/Final")
pdf("detectfunc_observer.pdf")
par(mfrow = c(4,2),
mar = c(2,3,1,2),
oma = c(2,4,1,1))
for (xxx in 1:length(s_good)){
# Select distance data (for bars of histogram per observer)
sp <- d[which(d$Species == s_good[xxx]), which(colnames(d) %in% c("Year", "Banda", "transectID", "T_Y", "Species", "Observer", "Cluster", "Temp", "distance"))] # Select species spAL and all years
#par(mfrow = c(1,2))
hist(sp$distance, breaks = c(0,25,50,99,200), main = " ", col = "grey") # Frequency ALL distances (for one species, all observers)
mtext("Frequency", side = 2, line = 3, cex = 0.7)
mtext(s_good[xxx], side = 2, line = 5, cex = 1.1)
ob <- unique(sp$Observer)
# Load model (for different sigma mean per observer)
setwd("S:/PhD/Second chapter/Data/Results/TRIM/compiled_final")
load(paste("HDS_",s_good[xxx],".RData", sep = ""))
sum <- out$summary
sigmas <- sum[grep("sig.obs", rownames(sum)), 1] # Sigmas are the log of the sigmas in reality?
exp.sig <- exp(sigmas) # Back transform to obtain sigma in the natural scale?????
curve(g(x, sig=exp.sig[1]), 0, 200, xlab="Distance (x)", ylab="Detection prob.", lwd = 2, frame = F, col = c[1], ylim = c(0,1))
mtext("Detection probability", side = 2, line = 3, cex = 0.7)
for (i in 2:length(ob)){ # For each species
curve(g(x, sig=exp.sig[i]), 0, 200, add=TRUE, lwd = 2, col = c[i])
}
}
setwd("S:/PhD/Second chapter/Data")
d <- read.csv("DataDS_ready_ALL.csv")
colnames(d)[which(colnames(d) == "Count")] <- "Cluster"
s_good <- c("MICAL", "PADOM", "MEAPI", "TERAX")
c <- palette(rainbow(15))
# 2. Define detection function
g <- function(x, sig) exp(-x^2/(2*sig^2))
x <- runif(40, 0, 200)
par(mfrow = c(4,2),
mar = c(2,3,1,2),
oma = c(2,4,1,1))
for (xxx in 1:length(s_good)){
# Select distance data (for bars of histogram per observer)
sp <- d[which(d$Species == s_good[xxx]), which(colnames(d) %in% c("Year", "Banda", "transectID", "T_Y", "Species", "Observer", "Cluster", "Temp", "distance"))] # Select species spAL and all years
#par(mfrow = c(1,2))
hist(sp$distance, breaks = c(0,25,50,99,200), main = " ", col = "grey") # Frequency ALL distances (for one species, all observers)
mtext("Frequency", side = 2, line = 3, cex = 0.7)
mtext(s_good[xxx], side = 2, line = 5, cex = 1.1)
ob <- unique(sp$Observer)
# Load model (for different sigma mean per observer)
setwd("S:/PhD/Second chapter/Data/Results/TRIM/compiled_final")
load(paste("HDS_",s_good[xxx],".RData", sep = ""))
sum <- out$summary
sigmas <- sum[grep("sig.obs", rownames(sum)), 1] # Sigmas are the log of the sigmas in reality?
exp.sig <- exp(sigmas) # Back transform to obtain sigma in the natural scale?????
curve(g(x, sig=exp.sig[1]), 0, 200, xlab="Distance (x)", ylab="Detection prob.", lwd = 2, frame = F, col = c[1], ylim = c(0,1))
mtext("Detection probability", side = 2, line = 3, cex = 0.7)
for (i in 2:length(ob)){ # For each species
curve(g(x, sig=exp.sig[i]), 0, 200, add=TRUE, lwd = 2, col = c[i])
}
}
mtext("Distance (m)", side = 1, line = 1, cex = 0.8, outer = TRUE)
par(mfrow = c(4,2),
mar = c(2,3,1,2),
oma = c(2,4,1,1))
for (xxx in 1:length(s_good)){
# Select distance data (for bars of histogram per observer)
sp <- d[which(d$Species == s_good[xxx]), which(colnames(d) %in% c("Year", "Banda", "transectID", "T_Y", "Species", "Observer", "Cluster", "Temp", "distance"))] # Select species spAL and all years
#par(mfrow = c(1,2))
hist(sp$distance, breaks = c(0,25,50,99,200), main = " ", col = "grey") # Frequency ALL distances (for one species, all observers)
mtext("Frequency", side = 2, line = 3, cex = 0.7)
mtext(s_good[xxx], side = 2, line = 5, cex = 1.1)
ob <- unique(sp$Observer)
# Load model (for different sigma mean per observer)
setwd("S:/PhD/Second chapter/Data/Results/TRIM/compiled_final")
load(paste("HDS_",s_good[xxx],".RData", sep = ""))
sum <- out$summary
sigmas <- sum[grep("sig.obs", rownames(sum)), 1] # Sigmas are the log of the sigmas in reality?
exp.sig <- exp(sigmas) # Back transform to obtain sigma in the natural scale?????
curve(g(x, sig=exp.sig[1]), 0, 200, xlab="Distance (x)", ylab="Detection prob.", lwd = 2, frame = F, col = c[1], ylim = c(0,1))
mtext("Detection probability", side = 2, line = 3, cex = 0.7)
for (i in 2:length(ob)){ # For each species
curve(g(x, sig=exp.sig[i]), 0, 200, add=TRUE, lwd = 2, col = c[i])
}
}
par(mfrow = c(4,2),
mar = c(2,3,1,2),
oma = c(2,4,1,1))
for (xxx in 1:length(s_good)){
# Select distance data (for bars of histogram per observer)
sp <- d[which(d$Species == s_good[xxx]), which(colnames(d) %in% c("Year", "Banda", "transectID", "T_Y", "Species", "Observer", "Cluster", "Temp", "distance"))] # Select species spAL and all years
#par(mfrow = c(1,2))
hist(sp$distance, breaks = c(0,25,50,99,200), main = " ", col = "grey") # Frequency ALL distances (for one species, all observers)
mtext("Frequency", side = 2, line = 3, cex = 0.7)
mtext(s_good[xxx], side = 2, line = 5, cex = 1.1)
ob <- unique(sp$Observer)
# Load model (for different sigma mean per observer)
setwd("S:/PhD/Second chapter/Data/Results/TRIM/compiled_final")
load(paste("HDS_",s_good[xxx],".RData", sep = ""))
sum <- out$summary
sigmas <- sum[grep("sig.obs", rownames(sum)), 1] # Sigmas are the log of the sigmas in reality?
exp.sig <- exp(sigmas) # Back transform to obtain sigma in the natural scale?????
curve(g(x, sig=exp.sig[1]), 0, 200, xlab="Distance (x)", ylab="Detection prob.", lwd = 2, frame = F, col = c[1], ylim = c(0,1))
mtext("Detection probability", side = 2, line = 3, cex = 0.7)
for (i in 2:length(ob)){ # For each species
curve(g(x, sig=exp.sig[i]), 0, 200, add=TRUE, lwd = 2, col = c[i])
}
}
mtext("Distance (m)", side = 1, line = 1, cex = 0.8, outer = TRUE)
curve(g(x, sig=exp.sig[1]), 0, 200, xlab="Distance (x)", ylab="Detection prob.", lwd = 2, frame = F, col = c[1], ylim = c(0,1))
mtext("Detection probability", side = 2, line = 3, cex = 0.7)
par(mfrow = c(4,2),
mar = c(2,3,1,2),
oma = c(2,4,1,1))
for (xxx in 1:length(s_good)){
# Select distance data (for bars of histogram per observer)
sp <- d[which(d$Species == s_good[xxx]), which(colnames(d) %in% c("Year", "Banda", "transectID", "T_Y", "Species", "Observer", "Cluster", "Temp", "distance"))] # Select species spAL and all years
#par(mfrow = c(1,2))
hist(sp$distance, breaks = c(0,25,50,99,200), main = " ", col = "grey") # Frequency ALL distances (for one species, all observers)
mtext("Frequency", side = 2, line = 3, cex = 0.7)
mtext(s_good[xxx], side = 2, line = 5, cex = 1.1)
ob <- unique(sp$Observer)
# Load model (for different sigma mean per observer)
setwd("S:/PhD/Second chapter/Data/Results/TRIM/compiled_final")
load(paste("HDS_",s_good[xxx],".RData", sep = ""))
sum <- out$summary
sigmas <- sum[grep("sig.obs", rownames(sum)), 1] # Sigmas are the log of the sigmas in reality?
exp.sig <- exp(sigmas) # Back transform to obtain sigma in the natural scale?????
curve(g(x, sig=exp.sig[1]), 0, 200, xlab="Distance (x)", ylab="Detection prob.", lwd = 2, frame = F, col = c[1], ylim = c(0,1))
mtext("Detection probability", side = 2, line = 3, cex = 0.7)
for (i in 2:length(ob)){ # For each species
curve(g(x, sig=exp.sig[i]), 0, 200, add=TRUE, lwd = 2, col = c[i])
}
}
mtext("Distance (m)", side = 1, line = 1, cex = 0.8, outer = TRUE)
setwd("S:/PhD/Second chapter/Data")
d <- read.csv("DataDS_ready_ALL.csv")
colnames(d)[which(colnames(d) == "Count")] <- "Cluster"
s_good <- c("MICAL", "PADOM", "MEAPI", "TERAX")
c <- palette(rainbow(15))
# 2. Define detection function
g <- function(x, sig) exp(-x^2/(2*sig^2))
x <- runif(40, 0, 200)
setwd("S:/PhD/Second chapter/Data/Results/Final")
par(mfrow = c(4,2),
mar = c(2,3,1,2),
oma = c(2,4,1,1))
for (xxx in 1:length(s_good)){
# Select distance data (for bars of histogram per observer)
sp <- d[which(d$Species == s_good[xxx]), which(colnames(d) %in% c("Year", "Banda", "transectID", "T_Y", "Species", "Observer", "Cluster", "Temp", "distance"))] # Select species spAL and all years
#par(mfrow = c(1,2))
hist(sp$distance, breaks = c(0,25,50,99,200), main = " ", col = "grey") # Frequency ALL distances (for one species, all observers)
mtext("Frequency", side = 2, line = 3, cex = 0.7)
mtext(s_good[xxx], side = 2, line = 5, cex = 1.1)
ob <- unique(sp$Observer)
# Load model (for different sigma mean per observer)
setwd("S:/PhD/Second chapter/Data/Results/TRIM/compiled_final")
load(paste("HDS_",s_good[xxx],".RData", sep = ""))
sum <- out$summary
sigmas <- sum[grep("sig.obs", rownames(sum)), 1] # Sigmas are the log of the sigmas in reality?
exp.sig <- exp(sigmas) # Back transform to obtain sigma in the natural scale?????
curve(g(x, sig=exp.sig[1]), 0, 200, xlab="Distance (x)", ylab="Detection prob.", lwd = 2, frame = F, col = c[1], ylim = c(0,1))
mtext("Detection probability", side = 2, line = 3, cex = 0.7)
for (i in 2:length(ob)){ # For each species
curve(g(x, sig=exp.sig[i]), 0, 200, add=TRUE, lwd = 2, col = c[i])
}
}
mtext("Distance (m)", side = 1, line = 1, cex = 0.8, outer = TRUE)
par(mfrow = c(4,2),
mar = c(2,3,1,2),
oma = c(2,4,1,1))
for (xxx in 1:length(s_good)){
# Select distance data (for bars of histogram per observer)
sp <- d[which(d$Species == s_good[xxx]), which(colnames(d) %in% c("Year", "Banda", "transectID", "T_Y", "Species", "Observer", "Cluster", "Temp", "distance"))] # Select species spAL and all years
#par(mfrow = c(1,2))
hist(sp$distance, breaks = c(0,25,50,99,200), main = " ", col = "grey") # Frequency ALL distances (for one species, all observers)
mtext("Frequency", side = 2, line = 3, cex = 0.7)
mtext(s_good[xxx], side = 2, line = 5, cex = 1.1)
ob <- unique(sp$Observer)
# Load model (for different sigma mean per observer)
setwd("S:/PhD/Second chapter/Data/Results/TRIM/compiled_final")
load(paste("HDS_",s_good[xxx],".RData", sep = ""))
sum <- out$summary
sigmas <- sum[grep("sig.obs", rownames(sum)), 1] # Sigmas are the log of the sigmas in reality?
exp.sig <- exp(sigmas) # Back transform to obtain sigma in the natural scale?????
curve(g(x, sig=exp.sig[1]), 0, 200, xlab="Distance (x)", ylab="Detection prob.", lwd = 2, frame = F, col = c[1], ylim = c(0,1))
mtext("Detection probability", side = 2, line = 3, cex = 0.7)
for (i in 2:length(ob)){ # For each species
curve(g(x, sig=exp.sig[i]), 0, 200, add=TRUE, lwd = 2, col = c[i])
}
}
mtext("Distance (m)", side = 1, line = 1, cex = 0.8, outer = TRUE)
c <- palette(rainbow(15))
c
g <- function(x, sig) exp(-x^2/(2*sig^2))
x <- runif(40, 0, 200)
par(mfrow = c(4,2),
mar = c(2,3,1,2),
oma = c(2,4,1,1))
for (xxx in 1:length(s_good)){
# Select distance data (for bars of histogram per observer)
sp <- d[which(d$Species == s_good[xxx]), which(colnames(d) %in% c("Year", "Banda", "transectID", "T_Y", "Species", "Observer", "Cluster", "Temp", "distance"))] # Select species spAL and all years
#par(mfrow = c(1,2))
hist(sp$distance, breaks = c(0,25,50,99,200), main = " ", col = "grey") # Frequency ALL distances (for one species, all observers)
mtext("Frequency", side = 2, line = 3, cex = 0.7)
mtext(s_good[xxx], side = 2, line = 5, cex = 1.1)
ob <- unique(sp$Observer)
# Load model (for different sigma mean per observer)
setwd("S:/PhD/Second chapter/Data/Results/TRIM/compiled_final")
load(paste("HDS_",s_good[xxx],".RData", sep = ""))
sum <- out$summary
sigmas <- sum[grep("sig.obs", rownames(sum)), 1] # Sigmas are the log of the sigmas in reality?
exp.sig <- exp(sigmas) # Back transform to obtain sigma in the natural scale?????
curve(g(x, sig=exp.sig[1]), 0, 200, xlab="Distance (x)", ylab="Detection prob.", lwd = 2, frame = F, col = c[1], ylim = c(0,1))
mtext("Detection probability", side = 2, line = 3, cex = 0.7)
for (i in 2:length(ob)){ # For each species
curve(g(x, sig=exp.sig[i]), 0, 200, add=TRUE, lwd = 2, col = c[i])
}
}
mtext("Distance (m)", side = 1, line = 1, cex = 0.8, outer = TRUE)
s_good <- c("ALRUF","BUOED","CACAR","COOEN","COPAL","GACRI","GATHE","MEAPI","MECAL","PAMAJ","SESER","STSSP","SYCAN","SYMEL","TERAX","UPEPO",
"MICAL","HIRUS","PADOM","PIPIC","PAMON", "COMON")
s_good <- sort(s_good)
par(mfrow = c(5,2),
mar = c(2,3,1,2),
oma = c(2,4,1,1))
for (xxx in 1:10){
# Select distance data (for bars of histogram per observer)
sp <- d[which(d$Species == s_good[xxx]), which(colnames(d) %in% c("Year", "Banda", "transectID", "T_Y", "Species", "Observer", "Cluster", "Temp", "distance"))] # Select species spAL and all years
ob <- unique(sp$Observer)
# Load model (for different sigma mean per observer)
setwd("S:/PhD/Second chapter/Data/Results/TRIM/6temp")
load(paste("HDS_",s_good[xxx],".RData", sep = ""))
sum <- out$summary
sigmas <- sum[grep("sig.obs", rownames(sum)), 1] # Sigmas are the log of the sigmas in reality?
exp.sig <- exp(sigmas) # Back transform to obtain sigma in the natural scale?????
curve(g(x, sig=exp.sig[1]), 0, 200, xlab="Distance (x)", ylab=s_good[xxx], lwd = 2, frame = F, col = c[1], ylim = c(0,1))
mtext("Detection probability", side = 2, line = 3, cex = 0.7)
for (i in 2:length(ob)){ # For each species
curve(g(x, sig=exp.sig[i]), 0, 200, add=TRUE, lwd = 2, col = c[i])
}
}
xxx = 1
# Select distance data (for bars of histogram per observer)
sp <- d[which(d$Species == s_good[xxx]), which(colnames(d) %in% c("Year", "Banda", "transectID", "T_Y", "Species", "Observer", "Cluster", "Temp", "distance"))] # Select species spAL and all years
ob <- unique(sp$Observer)
# Load model (for different sigma mean per observer)
setwd("S:/PhD/Second chapter/Data/Results/TRIM/6temp")
# Load model (for different sigma mean per observer)
setwd("S:/PhD/Second chapter/Data/Results/TRIM/compiled_final")
load(paste("HDS_",s_good[xxx],".RData", sep = ""))
sum <- out$summary
sigmas <- sum[grep("sig.obs", rownames(sum)), 1] # Sigmas are the log of the sigmas in reality?
exp.sig <- exp(sigmas) # Back transform to obtain sigma in the natural scale?????
curve(g(x, sig=exp.sig[1]), 0, 200, xlab="Distance (x)", ylab=s_good[xxx], lwd = 2, frame = F, col = c[1], ylim = c(0,1))
par(mfrow = c(5,2),
mar = c(2,3,1,2),
oma = c(2,4,1,1))
for (xxx in 1:10){
# Select distance data (for bars of histogram per observer)
sp <- d[which(d$Species == s_good[xxx]), which(colnames(d) %in% c("Year", "Banda", "transectID", "T_Y", "Species", "Observer", "Cluster", "Temp", "distance"))] # Select species spAL and all years
ob <- unique(sp$Observer)
# Load model (for different sigma mean per observer)
setwd("S:/PhD/Second chapter/Data/Results/TRIM/compiled_final")
load(paste("HDS_",s_good[xxx],".RData", sep = ""))
sum <- out$summary
sigmas <- sum[grep("sig.obs", rownames(sum)), 1] # Sigmas are the log of the sigmas in reality?
exp.sig <- exp(sigmas) # Back transform to obtain sigma in the natural scale?????
curve(g(x, sig=exp.sig[1]), 0, 200, xlab="Distance (x)", ylab= " ", lwd = 2, frame = F, col = c[1], ylim = c(0,1))
mtext(s_good[xxx], side = 2, line = 3, cex = 0.7)
for (i in 2:length(ob)){ # For each species
curve(g(x, sig=exp.sig[i]), 0, 200, add=TRUE, lwd = 2, col = c[i])
}
}
mtext("Distance (m)", side = 1, line = 1, cex = 0.8, outer = TRUE)
mtext("Detection probability", side = 2, line = 1, cex = 0.8, outer = TRUE)
mtext("Detection probability", side = 2, line = 2, cex = 0.8, outer = TRUE)
s_good <- c("ALRUF","BUOED","CACAR","COOEN","COPAL","GACRI","GATHE","MEAPI","MECAL","PAMAJ","SESER","STSSP","SYCAN","SYMEL","TERAX","UPEPO",
"MICAL","HIRUS","PADOM","PIPIC","PAMON", "COMON")
s_good <- sort(s_good)
par(mfrow = c(5,2),
mar = c(2,3,1,2),
oma = c(2,4,1,1))
for (xxx in 1:10){
# Select distance data (for bars of histogram per observer)
sp <- d[which(d$Species == s_good[xxx]), which(colnames(d) %in% c("Year", "Banda", "transectID", "T_Y", "Species", "Observer", "Cluster", "Temp", "distance"))] # Select species spAL and all years
ob <- unique(sp$Observer)
# Load model (for different sigma mean per observer)
setwd("S:/PhD/Second chapter/Data/Results/TRIM/compiled_final")
load(paste("HDS_",s_good[xxx],".RData", sep = ""))
sum <- out$summary
sigmas <- sum[grep("sig.obs", rownames(sum)), 1] # Sigmas are the log of the sigmas in reality?
exp.sig <- exp(sigmas) # Back transform to obtain sigma in the natural scale?????
curve(g(x, sig=exp.sig[1]), 0, 200, xlab="Distance (x)", ylab= " ", lwd = 2, frame = F, col = c[1], ylim = c(0,1))
mtext(s_good[xxx], side = 2, line = 3, cex = 0.7)
for (i in 2:length(ob)){ # For each species
curve(g(x, sig=exp.sig[i]), 0, 200, add=TRUE, lwd = 2, col = c[i])
}
}
mtext("Distance (m)", side = 1, line = 1, cex = 0.8, outer = TRUE)
mtext("Detection probability", side = 2, line = 2, cex = 0.8, outer = TRUE)
which(s_good %in% c("MICAL", "PADOM", "MEAPI", "TERAX"))
s_good <- s_good[-which(s_good %in% c("MICAL", "PADOM", "MEAPI", "TERAX"))]
s_good
par(mfrow = c(4,2),
mar = c(2,3,1,2),
oma = c(2,4,1,1))
for (xxx in 11:18){
# Select distance data (for bars of histogram per observer)
sp <- d[which(d$Species == s_good[xxx]), which(colnames(d) %in% c("Year", "Banda", "transectID", "T_Y", "Species", "Observer", "Cluster", "Temp", "distance"))] # Select species spAL and all years
ob <- unique(sp$Observer)
# Load model (for different sigma mean per observer)
setwd("S:/PhD/Second chapter/Data/Results/TRIM/compiled_final")
load(paste("HDS_",s_good[xxx],".RData", sep = ""))
sum <- out$summary
sigmas <- sum[grep("sig.obs", rownames(sum)), 1] # Sigmas are the log of the sigmas in reality?
exp.sig <- exp(sigmas) # Back transform to obtain sigma in the natural scale?????
curve(g(x, sig=exp.sig[1]), 0, 200, xlab="Distance (x)", ylab= " ", lwd = 2, frame = F, col = c[1], ylim = c(0,1))
mtext(s_good[xxx], side = 2, line = 3, cex = 0.7)
for (i in 2:length(ob)){ # For each species
curve(g(x, sig=exp.sig[i]), 0, 200, add=TRUE, lwd = 2, col = c[i])
}
}
mtext("Distance (m)", side = 1, line = 1, cex = 0.8, outer = TRUE)
mtext("Detection probability", side = 2, line = 2, cex = 0.8, outer = TRUE)
119+139+144+134+143+138+124+142
3*22
3*100
300/22
library(dplyr)
# 1. Number of transects per year
setwd("S:/PhD/Second chapter/Data")
d <- read.csv("DataDS_ready_ALL.csv")
d_transects <- d[ ,which(colnames(d) %in% c("Year", "T_Y", "transectID"))]
d_transects <- d_transects[which(!duplicated(d_transects$T_Y)), ]
trans <- aggregate(transectID ~ Year, data = d_transects, FUN = length)
colnames(trans)[2] <- "Number of transects"
trans
View(d)
s_good <- sort(s_good)
# Add species summary
s_good <- c("ALRUF","BUOED","CACAR","COOEN","COPAL","GACRI","GATHE","MEAPI","MECAL","PAMAJ","SESER","STSSP","SYCAN","SYMEL","TERAX","UPEPO",
"MICAL","HIRUS","PADOM","PIPIC","PAMON", "COMON")
s_good <- sort(s_good)
d_sp < d[which(d$Species == s_good[i]), ]
i = 1
d_sp < d[which(d$Species == s_good[i]), ]
d_sp <- d[which(d$Species == s_good[i]), ]
d_sp
year <- c(2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018)
d_t <- d_sp[which(d$Year == year[t]), ]
d_t <- d_sp[which(d_sp$Year == year[t]), ]
t = 1
d_t <- d_sp[which(d_sp$Year == year[t]), ]
d_t
View(d_t)
n_transects <-
prop_sp <- data.frame(ncol = length(year), nrow = length(s_good))
n_transects <-
prop_sp <- data.frame(ncol = length(year), nrow = length(s_good))
?data.frame
n_transects <-
prop_sp <- as.data.frame(matrix(ncol = length(year), nrow = length(s_good)))
prop_sp
rownames(prop_sp) <- s_good
colnames(prop_sp) <- year
prop_sp
trans
n_transects <- trans$`Number of transects`
n_transects
View(d_t)
unique(d_t$T_Y)
d_prop <- length(unique(d_t$T_Y))
d_prop
d_prop <- (length(unique(d_t$T_Y))/n_transects[t])*100
d_prop
prop_sp[i,t] <- d_prop
prop_sp
for (i in 1:length(s_good)){
d_sp <- d[which(d$Species == s_good[i]), ]
for (t in 1:9){
d_t <- d_sp[which(d_sp$Year == year[t]), ]
d_prop <- (length(unique(d_t$T_Y))/n_transects[t])*100
prop_sp[i,t] <- d_prop
}
}
prop_sp
prop_sp <- round(prop_sp,2)
prop_sp
yearly_avg <- summarise_each(prop_sp, funs = mean)
yearly_avg <- summarise_all(prop_sp, funs = mean)
yearly_avg <- summarise_each(prop_sp, funs(mean))
yearly_avg <- summarise_all(prop_sp, funs(mean))
yearly_avg
?apply
apply(prop_sp,1,mean)
mean_sp_presence <- apply(prop_sp,1,mean)
mean_sp_presence <- apply(prop_sp,1,mean)
mean_sp_presence
prop_sp$avg <- apply(prop_sp,1,mean)
prop_sp
prop_sp$avg <- round(apply(prop_sp,1,mean), 2)
prop_sp
prop_sp
prop_sp
max(prop_sp$avg)
min(prop_sp$avg)
sort(prop_sp$avg)
arrange(prop_sp,avg)
library(dplyr)
# 1. Number of transects per year
setwd("S:/PhD/Second chapter/Data")
d <- read.csv("DataDS_ready_ALL.csv")
d_transects <- d[ ,which(colnames(d) %in% c("Year", "T_Y", "transectID"))]
d_transects <- d_transects[which(!duplicated(d_transects$T_Y)), ]
trans <- aggregate(transectID ~ Year, data = d_transects, FUN = length)
colnames(trans)[2] <- "Number of transects"
trans
setwd("S:/PhD/Second chapter/Data")
d <- read.csv("DataDS_ready_ALL.csv")
d$Observer <- as.numeric(d$Observer)
year <- c("2010", "2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018")
ob_table <- d %>% group_by(Year) %>% summarise(n_distinct(Observer)) # Check:
ob <- list()
for (i in 1:9){
d_y <- d[which(d$Year == year[i]),]
Nob <- unique(d_y$Observer)
ob[[i]] <- Nob
}
library(plyr)
ob1 <- ldply(ob, rbind)
ob1 <- as.data.frame(t(ob1))
colnames(ob1) <- c("2010", "2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018")
nrows(ob1[which(complete.cases(ob1)), ])
n_obs <- !is.na(ob1)
n_obs <- colSums(n_obs)
t(n_obs)
s_good <- c("ALRUF","BUOED","CACAR","COOEN","COPAL","GACRI","GATHE","MEAPI","MECAL","PAMAJ","SESER","STSSP","SYCAN","SYMEL","TERAX","UPEPO",
"MICAL","HIRUS","PADOM","PIPIC","PAMON", "COMON")
s_good <- sort(s_good)
year <- c(2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018)
n_transects <- trans$`Number of transects`
prop_sp <- as.data.frame(matrix(ncol = length(year), nrow = length(s_good)))
rownames(prop_sp) <- s_good
colnames(prop_sp) <- year
for (i in 1:length(s_good)){
d_sp <- d[which(d$Species == s_good[i]), ]
for (t in 1:9){
d_t <- d_sp[which(d_sp$Year == year[t]), ]
d_prop <- (length(unique(d_t$T_Y))/n_transects[t])*100
prop_sp[i,t] <- d_prop
}
}
prop_sp <- round(prop_sp,2)
prop_sp$avg <- round(apply(prop_sp,1,mean), 2) # average of species occupancy in transects
max(prop_sp$avg)
min(prop_sp$avg)
arrange(prop_sp,avg)
yearly_avg <- summarise_all(prop_sp, funs(mean))
prop_sp
s_good <- c("ALRUF","BUOED","CACAR","COOEN","COPAL","GACRI","GATHE","MEAPI","MECAL","PAMAJ","SESER","STSSP","SYCAN","SYMEL","TERAX","UPEPO",
"MICAL","HIRUS","PADOM","PIPIC","PAMON", "COMON")
s_good <- sort(s_good)
year <- c(2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018)
n_transects <- trans$`Number of transects`
prop_sp <- as.data.frame(matrix(ncol = length(year), nrow = length(s_good)))
rownames(prop_sp) <- s_good
colnames(prop_sp) <- year
for (i in 1:length(s_good)){
d_sp <- d[which(d$Species == s_good[i]), ]
for (t in 1:9){
d_t <- d_sp[which(d_sp$Year == year[t]), ]
d_prop <- (length(unique(d_t$T_Y))/n_transects[t])*100
prop_sp[i,t] <- d_prop
}
}
prop_sp <- round(prop_sp,2)
prop_sp$Mean_proportion <- round(apply(prop_sp,1,mean), 2)
setwd("S:/PhD/Second chapter/Data/Results/Paper")
write.csv(prop_sp, "TableSI2_sp_prop.csv")
