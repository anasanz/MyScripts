# 1. Calculate predictions for both zones
outall <- do.call(rbind,out$samples)
# Total population (since both follow the same trend)
pred.exp <- matrix(NA, dim(outall)[1], length(yrs2))
for(i in 1:dim(outall)[1]){
##calculate population, year 1
pred.exp[i,1] <- as.vector(outall[i,"lam.tot[1]"])
##calculate populations, year 2-8, based on beta(Year)
for (t in 2:length(yrs2)){
pred.exp[i,t] <- pred.exp[i,(t-1)] * # Here I add the starting population size as a baseline for the trend
exp(outall[i,"bYear.lam"])
}
}
predall.exp <- pred.exp
lci.exp <- uci.exp <- mean.pred.exp <- 0
for(i in 1:length(yrs2)){
lci.exp[i]  <- quantile(predall.exp[,i],probs = 0.025)
uci.exp[i]  <- quantile(predall.exp[,i],probs = 0.975)
mean.pred.exp[i]  <- mean(predall.exp[,i])
}
est_hds <- round(results[3,1],2)
significance_est_hds <- ifelse(results[3,10] == 0,
paste(est_hds,"*", sep = ""),
est_hds)
##############################################################################################################
################################           PLOT                   ##########################################
###########################################################################################################
#Plot Both
pop <- out$summary[grep("popindex", rownames(out$summary)),1]
max_range <- max(uci.exp,tot$imputed, pop[1:9])
yrs2 <- c(2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018)
# Load function with both graphs. You should have loaded first all results from both trim and hds and then load this function
setwd("C:/Users/Ana/Documents/PhD/MyScripts/Ch. 2-3/Ch. 2/Results")
source("plot_trim_hds1.R")
plot.trim.hds.overall_yo1(overall(m3), yrange = c(0, max_range))
################################################################
# If only the function for trim is runned(plot.trim.overall_yo), you have to run this for the hds model:
# PLOT HDS
#polygon( x = c(yrs2, rev(yrs2)),
#         y = c(lci.exp, rev(uci.exp)),
#         col = adjustcolor(c("grey"),alpha.f = 0.6),
#         border = NA)
#
#points(yrs2, out$summary[grep("popindex", rownames(out$summary)),1], pch = 19, type = "l", col= adjustcolor("black",alpha.f = 0.4))
#points(yrs2, out$summary[grep("popindex", rownames(out$summary)),1], pch = 19, type = "p", col= "white", cex = 1.5)
#points(yrs2, out$summary[grep("popindex", rownames(out$summary)),1], pch = 19, type = "p", col= adjustcolor("black",alpha.f = 0.4), cex = 1.5)
#
#points(mean.pred.exp ~ yrs2, type="l", col= "black", lwd = 2)
}
#1. Plot last plot with function plot.trim.hds.overall_yo2 (that contains x-axes)
for (xxx in 10:11){
d_tr <- d[ ,which(colnames(d) %in% c("Species",  "T_Y", "Observer"))]
d_tr_all <- data.frame(T_Y = unique(d_tr$T_Y), id = NA)
d_tr$Observer <- as.character(d_tr$Observer)
d_tr_all_obs <- left_join(d_tr_all, d_tr)
d_tr_all_obs <- d_tr_all_obs[ ,c(1,4)]
d_tr_all_obs <- d_tr_all_obs[which(!duplicated(d_tr_all_obs)), ] # Table with all sampled fields and which observer sampled it
sp <- d[which(d$Species == s_good[xxx]), which(colnames(d) %in% c("Year", "Banda", "transectID", "T_Y", "Species", "Observer", "Cluster"))] # Select species spAL and all years
sp <- arrange(sp, Year, transectID) #Ordered
sp_detec_transectID <- unique(sp$transectID)
sp$Observer <- as.character(sp$Observer)
absent <- anti_join(d_tr_all,sp) # Transects with 0 abundance, add to sp.
colnames(absent)[2] <- "Banda" # Format it to add the rows to sp
absent$T_Y <- as.character(absent$T_Y)
absent$Species <- s_good[xxx]
absent$Cluster <- NA
absent <- left_join(absent, d_tr_all_obs)
for (i in 1:nrow(absent)){ # Format to join absent - detections
cent <- substr(absent$T_Y[i], 10,10) # To include SI102 (cents)
cent <- as.numeric(cent)
if(is.na(cent)){
absent$Year[i] <- substr(absent$T_Y[i], 6,9)
absent$transectID[i] <- substr(absent$T_Y[i], 1,4)
} else { absent$Year[i] <- substr(absent$T_Y[i], 7,10)
absent$transectID[i] <- substr(absent$T_Y[i], 1,5)}
}
absent$count <- 0
sp$count <- 1
all_sp <- rbind(sp,absent) # Include transects with abundance 0
all_sp <- arrange(all_sp, Year, transectID) # Ordered
absent$count <- 0
sp <- all_sp[, which(colnames(all_sp) %in% c("Year", "transectID", "count"))] # Select species MECAL and all years
colnames(sp)[which(colnames(sp) %in% "transectID")] <- "site"
colnames(sp)[which(colnames(sp) %in% "Year")] <- "year"
sp$year <- as.integer(sp$year)
g <- aggregate(count ~ year, FUN = sum, data = sp)
sp <- aggregate(count ~ year + site, FUN = sum, data = sp)
check_observations(sp, model = 2)
# Model 3
m3 <- trim(count ~ site + year, data = sp, model = 3)
i3 <- index(m3, which="both")
#Extract the coefficients
coef <- coefficients(m3, representation = c("trend"))
coef_st <- coefficients(m3, representation = c("standard"))
coef_dev <- coefficients(m3, representation = c("deviations"))
sig_dev <- wald(m3)
tot <- totals(m3)
sig <- overall(m3) # The p-value of this is the significant value for the overall trend in m3, = p value of the slope of m2 with all change points
# Calculate 95% CI from se
lci <- coef$add - 2*coef$se_add
uci <- coef$add + 2*coef$se_add
cont_zero <- between(0,lci,uci)
est_trim <- round(coef$add[1], 2)
significance_est_ci_trim <- ifelse(cont_zero == FALSE,
paste(est_trim,"*", sep = ""),
est_trim)
# Calculate 95% CI for standard deviations
lci_dev <- vector()
uci_dev <- vector()
cont_zero <- vector()
cont_zero_dev <- vector()
for (i in 1:9){
lci_dev[i] <- coef_dev$add[i] - 2*coef_dev$se_add[i]
uci_dev[i] <- coef_dev$add[i] + 2*coef_dev$se_add[i]
cont_zero[i] <- between(0,lci_dev[i],uci_dev[i])
cont_zero_dev[i]<- as.numeric(cont_zero[i]) #if its FALSE (0) is significant deviations (it does not conatain 0)
}
cont_zero_dev <- ifelse(cont_zero_dev == 0, 1, 0) # swith for plot (significant deviations are represented by 1)
##############################################################################################################
################################           Output HDS              ##########################################
###########################################################################################################
setwd("C:/Users/Ana/Documents/PhD/Second chapter/Resubmission/Results/Compiled_FINAL")
load(paste("HDS_",s_good[xxx],".RData", sep = ""))
summary <- as.data.frame(out$summary)
results <- summary[which(rownames(summary) %in% c("popindex[1]", "popindex[2]", "popindex[3]", "popindex[4]", "popindex[5]", "popindex[6]", "popindex[7]", "popindex[8]", "popindex[9]",
"mu.lam.site", "sig.lam.site", "bzB.sig" , "bYear.lam")), ]
year_dev <- summary[grep("log.lambda.year", rownames(summary)), c(1,3,7,10)]
year_dev_hds <- year_dev$overlap0
year_dev_hds <- ifelse(year_dev_hds == 0, 1, 0)
year_dev_hds[1] <- 0
# CALCULATE CI
# Based on expected N
yrs2 <- c(0, 1, 2, 3, 4, 5, 6, 7, 8)
# 1. Calculate predictions for both zones
outall <- do.call(rbind,out$samples)
# Total population (since both follow the same trend)
pred.exp <- matrix(NA, dim(outall)[1], length(yrs2))
for(i in 1:dim(outall)[1]){
##calculate population, year 1
pred.exp[i,1] <- as.vector(outall[i,"lam.tot[1]"])
##calculate populations, year 2-8, based on beta(Year)
for (t in 2:length(yrs2)){
pred.exp[i,t] <- pred.exp[i,(t-1)] * # Here I add the starting population size as a baseline for the trend
exp(outall[i,"bYear.lam"])
}
}
predall.exp <- pred.exp
lci.exp <- uci.exp <- mean.pred.exp <- 0
for(i in 1:length(yrs2)){
lci.exp[i]  <- quantile(predall.exp[,i],probs = 0.025)
uci.exp[i]  <- quantile(predall.exp[,i],probs = 0.975)
mean.pred.exp[i]  <- mean(predall.exp[,i])
}
est_hds <- round(results[3,1],2)
significance_est_hds <- ifelse(results[3,10] == 0,
paste(est_hds,"*", sep = ""),
est_hds)
##############################################################################################################
################################           PLOT                   ##########################################
###########################################################################################################
#Plot Both
max_range <- max(uci.exp,tot$imputed, out$summary[grep("popindex", rownames(out$summary)),1])
yrs2 <- c(2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018)
# Load function with both graphs. You should have loaded first all results from both trim and hds to run this function
setwd("C:/Users/Ana/Documents/PhD/MyScripts/Ch. 2-3/Ch. 2/Results")
source("plot_trim_hds2.R")
plot.trim.hds.overall_yo2(overall(m3), yrange = c(0, max_range))
################################################################
# If only the function for trim is runned(plot.trim.overall_yo), you have to run this for the hds model:
# PLOT HDS
#polygon( x = c(yrs2, rev(yrs2)),
#         y = c(lci.exp, rev(uci.exp)),
#         col = adjustcolor(c("grey"),alpha.f = 0.6),
#         border = NA)
#
#points(yrs2, out$summary[grep("popindex", rownames(out$summary)),1], pch = 19, type = "l", col= adjustcolor("black",alpha.f = 0.4))
#points(yrs2, out$summary[grep("popindex", rownames(out$summary)),1], pch = 19, type = "p", col= "white", cex = 1.5)
#points(yrs2, out$summary[grep("popindex", rownames(out$summary)),1], pch = 19, type = "p", col= adjustcolor("black",alpha.f = 0.4), cex = 1.5)
#
#points(mean.pred.exp ~ yrs2, type="l", col= "black", lwd = 2)
mtext("Number of individuals", side = 2, line = 1, cex = 1, outer = TRUE)
mtext("Year", side = 1, line = 2, cex = 1, outer = TRUE)
}
dev.off()
rm(list=ls())
library(dplyr)
##############################################################################################################
################################           Temperature              ##########################################
###########################################################################################################
#### Check effect of temperature for species where it is significant for m6
s_good <- c("SYCAN", "CACHL", "LASEN", "ALRUF", "PAMAJ", "ALARV", "CABRA", "CACAR", "COPAL", "PIPIC",
"COOEN", "HIRUS", "PYRAX", "CAINA", "COMON", "PADOM", "PAMON", "FATIN", "SESER", "TUMER", "GATHE",
"BUOED", "SYMEL", "UPEPO", "GACRI", "STSSP", "MICAL", "MEAPI", "TERAX", "MECAL") # Species in order of appearance in the list
setwd("C:/Users/Ana/Documents/PhD/Second chapter/Resubmission/Results/Compiled_FINAL")
load("spConvergence_light_resub.RData")
##### Value for CI #####
temp <- data.frame(matrix(NA,ncol = 5,nrow = length(s_good)))
colnames(temp) <- c("sp", "est", "lci", "uci", "over_0")
for (i in 1:length(s_good)) {
sum <- data.frame(species[[i]][[2]])
est_temp <- sum[which(rownames(sum) %in% "bTemp.sig"), c(1,3,7,10)]
temp[i,1] <- s_good[i]
if(nrow(est_temp) == 0)
next
temp[i,c(2:5)] <- est_temp
}
temp_sig <- temp[which(temp$over_0 == 0), ] # Species which detection is detected by temperature
s_temp <- temp_sig$sp
temp <- cbind(temp[ ,1], round(temp[ ,c(2:5)],2))
setwd("S:/Results/chapter2/Plots")
write.csv(temp, "Table1.csv")
##############################################################################################################
######################           Bayesian p-values                ##########################################
###########################################################################################################
# Join Bayesian p-values
# Observation model
Bp6 <- data.frame(matrix(NA,ncol = 5,nrow = length(s_good)))
colnames(Bp6) <- c("sp", "Bp.Obs", "lci", "uci", "over_0")
for (i in 1:length(s_good)) {
sum <- data.frame(species[[i]][[2]])
est_Bp6 <- sum[which(rownames(sum) %in% "Bp.Obs"), c(1,3,7,10)]
Bp6[i,1] <- s_good[i]
Bp6[i,c(2:5)] <- est_Bp6
}
Bp6 <- Bp6[,c(1,2)]
Bp6_bad <- Bp6[which(Bp6$Bp.Obs < 0.1 | Bp6$Bp.Obs > 0.9), ] # Bad bayesian p-values
# Join with temperature
tab1 <- left_join(temp,Bp6, by = "sp")
# Abundance model
BpN6 <- data.frame(matrix(NA,ncol = 5,nrow = length(s_good)))
colnames(BpN6) <- c("sp", "Bp.N", "lci", "uci", "over_0")
for (i in 1:length(s_good)) {
sum <- data.frame(species[[i]][[2]])
est_BpN6 <- sum[which(rownames(sum) %in% "Bp.N"), c(1,3,7,10)]
BpN6[i,1] <- s_good[i]
BpN6[i,c(2:5)] <- est_BpN6
}
BpN6 <- BpN6[,c(1,2)]
BpN6_bad <- BpN6[which(BpN6$Bp.Obs < 0.1 | BpN6$Bp.Obs > 0.9), ] # Bad bayesian p-values
# Join all
tab2 <- left_join(tab1,BpN6, by = "sp")
tab2[,c(2,3,4,6,7)] <- round(tab2[,c(2,3,4,6,7)], digits = 3)
tab2$CI <- paste("[", tab2$lci, " - ", tab2$uci, "]", sep = "")
tab2 <- tab2[ ,c(1,2,8,6,7)]
tab3 <- arrange(tab2, sp)
rm(list=ls())
library(dplyr)
##############################################################################################################
################################           Temperature              ##########################################
###########################################################################################################
#### Check effect of temperature for species where it is significant for m6
s_good <- c("SYCAN", "CACHL", "LASEN", "ALRUF", "PAMAJ", "ALARV", "CABRA", "CACAR", "COPAL", "PIPIC",
"COOEN", "HIRUS", "PYRAX", "CAINA", "COMON", "PADOM", "PAMON", "FATIN", "SESER", "TUMER", "GATHE",
"BUOED", "SYMEL", "UPEPO", "GACRI", "STSSP", "MICAL", "MEAPI", "TERAX", "MECAL") # Species in order of appearance in the list
setwd("C:/Users/Ana/Documents/PhD/Second chapter/Resubmission/Results/Compiled_FINAL")
load("spConvergence_light_resub.RData")
temp <- data.frame(matrix(NA,ncol = 5,nrow = length(s_good)))
colnames(temp) <- c("sp", "est", "lci", "uci", "over_0")
for (i in 1:length(s_good)) {
sum <- data.frame(species[[i]][[2]])
est_temp <- sum[which(rownames(sum) %in% "bTemp.sig"), c(1,3,7,10)]
temp[i,1] <- s_good[i]
if(nrow(est_temp) == 0)
next
temp[i,c(2:5)] <- est_temp
}
temp_sig <- temp[which(temp$over_0 == 0), ] # Species which detection is detected by temperature
s_temp <- temp_sig$sp
temp <- cbind(temp[ ,1], round(temp[ ,c(2:5)],2))
#setwd("S:/Results/chapter2/Plots")
#write.csv(temp, "Table1.csv")
##############################################################################################################
######################           Bayesian p-values                ##########################################
###########################################################################################################
# Join Bayesian p-values
# Observation model
Bp6 <- data.frame(matrix(NA,ncol = 5,nrow = length(s_good)))
colnames(Bp6) <- c("sp", "Bp.Obs", "lci", "uci", "over_0")
for (i in 1:length(s_good)) {
sum <- data.frame(species[[i]][[2]])
est_Bp6 <- sum[which(rownames(sum) %in% "Bp.Obs"), c(1,3,7,10)]
Bp6[i,1] <- s_good[i]
Bp6[i,c(2:5)] <- est_Bp6
}
Bp6 <- Bp6[,c(1,2)]
Bp6_bad <- Bp6[which(Bp6$Bp.Obs < 0.1 | Bp6$Bp.Obs > 0.9), ] # Bad bayesian p-values
# Join with temperature
tab1 <- left_join(temp,Bp6, by = "sp")
# Abundance model
BpN6 <- data.frame(matrix(NA,ncol = 5,nrow = length(s_good)))
colnames(BpN6) <- c("sp", "Bp.N", "lci", "uci", "over_0")
for (i in 1:length(s_good)) {
sum <- data.frame(species[[i]][[2]])
est_BpN6 <- sum[which(rownames(sum) %in% "Bp.N"), c(1,3,7,10)]
BpN6[i,1] <- s_good[i]
BpN6[i,c(2:5)] <- est_BpN6
}
BpN6 <- BpN6[,c(1,2)]
BpN6_bad <- BpN6[which(BpN6$Bp.Obs < 0.1 | BpN6$Bp.Obs > 0.9), ] # Bad bayesian p-values
# Join all
tab2 <- left_join(tab1,BpN6, by = "sp")
tab2[,c(2,3,4,6,7)] <- round(tab2[,c(2,3,4,6,7)], digits = 3)
tab2$CI <- paste("[", tab2$lci, " - ", tab2$uci, "]", sep = "")
tab2 <- tab2[ ,c(1,2,8,6,7)]
tab3 <- arrange(tab2, sp)
library(dplyr)
setwd("C:/Users/Ana/Documents/PhD/Second chapter/Data")
leg <- read.csv("leg_species.csv", sep = ";")
leg <- arrange(leg,codiEspecie)
colnames(leg)[1] <- "sp"
View(temp)
rm(list=ls())
library(dplyr)
##############################################################################################################
################################           Temperature              ##########################################
###########################################################################################################
#### Check effect of temperature for species where it is significant for m6
s_good <- c("SYCAN", "CACHL", "LASEN", "ALRUF", "PAMAJ", "ALARV", "CABRA", "CACAR", "COPAL", "PIPIC",
"COOEN", "HIRUS", "PYRAX", "CAINA", "COMON", "PADOM", "PAMON", "FATIN", "SESER", "TUMER", "GATHE",
"BUOED", "SYMEL", "UPEPO", "GACRI", "STSSP", "MICAL", "MEAPI", "TERAX", "MECAL") # Species in order of appearance in the list
setwd("C:/Users/Ana/Documents/PhD/Second chapter/Resubmission/Results/Compiled_FINAL")
load("spConvergence_light_resub.RData")
##### Value for CI #####
temp <- data.frame(matrix(NA,ncol = 5,nrow = length(s_good)))
colnames(temp) <- c("sp", "est", "lci", "uci", "over_0")
for (i in 1:length(s_good)) {
sum <- data.frame(species[[i]][[2]])
est_temp <- sum[which(rownames(sum) %in% "bTemp.sig"), c(1,3,7,10)]
temp[i,1] <- s_good[i]
if(nrow(est_temp) == 0)
next
temp[i,c(2:5)] <- est_temp
}
temp_sig <- temp[which(temp$over_0 == 0), ] # Species which detection is detected by temperature
s_temp <- temp_sig$sp
temp <- cbind(temp[ ,1], round(temp[ ,c(2:5)],2))
View(temp)
colnames(temp)[1] <- "sp"
# Observation model
Bp6 <- data.frame(matrix(NA,ncol = 5,nrow = length(s_good)))
colnames(Bp6) <- c("sp", "Bp.Obs", "lci", "uci", "over_0")
for (i in 1:length(s_good)) {
sum <- data.frame(species[[i]][[2]])
est_Bp6 <- sum[which(rownames(sum) %in% "Bp.Obs"), c(1,3,7,10)]
Bp6[i,1] <- s_good[i]
Bp6[i,c(2:5)] <- est_Bp6
}
Bp6 <- Bp6[,c(1,2)]
Bp6_bad <- Bp6[which(Bp6$Bp.Obs < 0.1 | Bp6$Bp.Obs > 0.9), ] # Bad bayesian p-values
# Join with temperature
tab1 <- left_join(temp,Bp6, by = "sp")
BpN6 <- data.frame(matrix(NA,ncol = 5,nrow = length(s_good)))
colnames(BpN6) <- c("sp", "Bp.N", "lci", "uci", "over_0")
for (i in 1:length(s_good)) {
sum <- data.frame(species[[i]][[2]])
est_BpN6 <- sum[which(rownames(sum) %in% "Bp.N"), c(1,3,7,10)]
BpN6[i,1] <- s_good[i]
BpN6[i,c(2:5)] <- est_BpN6
}
BpN6 <- BpN6[,c(1,2)]
BpN6_bad <- BpN6[which(BpN6$Bp.Obs < 0.1 | BpN6$Bp.Obs > 0.9), ] # Bad bayesian p-values
# Join all
tab2 <- left_join(tab1,BpN6, by = "sp")
tab2[,c(2,3,4,6,7)] <- round(tab2[,c(2,3,4,6,7)], digits = 3)
tab2$CI <- paste("[", tab2$lci, " - ", tab2$uci, "]", sep = "")
tab2 <- tab2[ ,c(1,2,8,6,7)]
tab3 <- arrange(tab2, sp)
View(tab3)
library(dplyr)
setwd("C:/Users/Ana/Documents/PhD/Second chapter/Data")
leg <- read.csv("leg_species.csv", sep = ";")
leg <- arrange(leg,codiEspecie)
colnames(leg)[1] <- "sp"
tab4 <- left_join(tab3,leg)
View(tab4)
tab4 <- tab4[ ,c(7,2:5)]
tab4 <- left_join(tab3,leg)
tab4 <- tab4[ ,c(7,1:5)]
tab4 <- left_join(tab3,leg)
tab4 <- tab4[ ,c(1,7,2:5)]
setwd("C:/Users/Ana/Documents/PhD/Second chapter/Resubmission/Results/Final")
write.csv(tab3, "TableS4_temp_BP.csv")
setwd("C:/Users/Ana/Documents/PhD/Second chapter/Resubmission/Results/Final")
write.csv(tab3, "TableS4_temp_BP.csv")
write.csv(tab4, "TableS4_temp_BP.csv")
ab_zepa_sp <- list()
nzepas <- 8
nyears <- 9
ab_zepa <- matrix(NA, nrow = nzepas, ncol = nyears)
rownames(ab_zepa) <- c("AF", "AL", "BA", "BE", "BM", "GR", "NoZepa", "SI")
colnames(ab_zepa) <- c(2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018)
hr <- c("SYCAN", "CACHL", "LASEN", "ALRUF", "PAMAJ", "ALARV", "CABRA", "CACAR", "COPAL", "PIPIC",
"COOEN", "HIRUS", "PYRAX", "CAINA", "COMON", "PADOM", "PAMON", "FATIN", "SESER", "TUMER", "GATHE",
"BUOED", "SYMEL", "UPEPO", "GACRI", "STSSP", "MICAL", "MEAPI", "TERAX", "MECAL") # Species in order of appearance in the list
for (s in 1:length(hr)){
sum <- species[[s]][[2]]
sum <- round(sum, 2)
sum_zepa <- sum[grep("popindex_zepa", rownames(sum)), ]
for (t in 1:nyears){
sum_zepa_mean <- sum_zepa[grep(paste(t,"]", sep = ""), rownames(sum_zepa)), 1] # To get the mean
sum_zepa_sd <- sum_zepa[grep(paste(t,"]", sep = ""), rownames(sum_zepa)), 2] # To get the sd
ab_zepa[,t] <- as.character(paste(sum_zepa_mean, "+/-", sum_zepa_sd))
}
ab_zepa_sp[[s]] <- list(hr[s],ab_zepa)
}
hr <- c("SYCAN", "CACHL", "LASEN", "ALRUF", "PAMAJ", "ALARV", "CABRA", "CACAR", "COPAL", "PIPIC",
"COOEN", "HIRUS", "PYRAX", "CAINA", "COMON", "PADOM", "PAMON", "FATIN", "SESER", "TUMER", "GATHE",
"BUOED", "SYMEL", "UPEPO", "GACRI", "STSSP", "MICAL", "MEAPI", "TERAX", "MECAL") # Species in order of appearance in the list
setwd("C:/Users/Ana/Documents/PhD/Second chapter/Resubmission/Results/Compiled_FINAL")
load("spConvergence_light_resub.RData")
ab_zepa_sp <- list()
nzepas <- 8
nyears <- 9
ab_zepa <- matrix(NA, nrow = nzepas, ncol = nyears)
rownames(ab_zepa) <- c("AF", "AL", "BA", "BE", "BM", "GR", "NoZepa", "SI")
colnames(ab_zepa) <- c(2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018)
for (s in 1:length(hr)){
sum <- species[[s]][[2]]
sum <- round(sum, 2)
sum_zepa <- sum[grep("popindex_zepa", rownames(sum)), ]
for (t in 1:nyears){
sum_zepa_mean <- sum_zepa[grep(paste(t,"]", sep = ""), rownames(sum_zepa)), 1] # To get the mean
sum_zepa_sd <- sum_zepa[grep(paste(t,"]", sep = ""), rownames(sum_zepa)), 2] # To get the sd
ab_zepa[,t] <- as.character(paste(sum_zepa_mean, "+/-", sum_zepa_sd))
}
ab_zepa_sp[[s]] <- list(hr[s],ab_zepa)
}
for (i in 1:length(s_good)){ # to check that s_good and species are in the same order
print(species[[i]][[1]])
}
for (i in 1:length(hr)){ # to check that s_good and species are in the same order
print(species[[i]][[1]])
}
1:length(hr)
hr
alruf <- ab_zepa_sp[[4]]
buoed <- ab_zepa_sp[[22]]
comon <- ab_zepa_sp[[15]]
padom <- ab_zepa_sp[[16]]
View(alruf)
View(buoed)
View(comon)
View(padom)
alruf <- ab_zepa_sp[[4]][[2]]
View(alruf)
alruf <- ab_zepa_sp[[4]][[2]]
buoed <- ab_zepa_sp[[22]][[2]]
comon <- ab_zepa_sp[[15]][[2]]
padom <- ab_zepa_sp[[16]][[2]]
table <- rbind(alruf, buoed, comon, padom)
View(table)
alruf <- ab_zepa_sp[[4]][[2]]
buoed <- ab_zepa_sp[[22]][[2]]
comon <- ab_zepa_sp[[15]][[2]]
padom <- ab_zepa_sp[[16]][[2]]
alruf$sp <- "ALRUF"
buoed$sp <- "BUOED"
comon$sp <- "COMON"
padom$sp <- "PADOM"
table <- rbind(alruf, buoed, comon, padom)
View(alruf)
alruf <- ab_zepa_sp[[4]][[2]]
alruf <- ab_zepa_sp[[4]][[2]]
buoed <- ab_zepa_sp[[22]][[2]]
comon <- ab_zepa_sp[[15]][[2]]
padom <- ab_zepa_sp[[16]][[2]]
table <- rbind(alruf, buoed, comon, padom)
write.csv(table,"ab_spa.csv")
setwd("C:/Users/Ana/Documents/PhD/Second chapter/Resubmission/Results/Final")
write.csv(table,"ab_spa.csv")
rm(list=ls())
library(dplyr)
library(tidyr)
# 1. Number of transects per year
setwd("C:/Users/Ana/Documents/PhD/Second chapter/Resubmission")
d <- read.csv("DataDS_ready_ALL_revch2.csv")
d_transects <- d[ ,which(colnames(d) %in% c("Year", "T_Y", "transectID"))]
d_transects <- d_transects[which(!duplicated(d_transects$T_Y)), ]
trans <- aggregate(transectID ~ Year, data = d_transects, FUN = length)
colnames(trans)[2] <- "Number of transects"
trans
d_transects1 <- d_transects[ ,-which(colnames(d_transects) %in% c("T_Y"))]
d_transects
d_transects1 <- d_transects[ ,-which(colnames(d_transects) %in% c("T_Y"))]
d_transects1$transectID2 <- d_transects1$transectID
d_transects2 <- spread(d_transects1, Year, transectID)
nrow(d_transects2)
nrow(d_transects2[complete.cases(d_transects2), ])/nrow(d_transects2) # % of transects sampled every year
View(d_transects2)
nrow(d_transects2)
nas <- function(x){
num_na <- sum(is.na(x))
return(num_na)
}
number_nas <- apply(d_transects2[,c(2:10)],1, function (x) nas(x))
length(number_nas[which(number_nas == 0)])/nrow(d_transects2)
length(number_nas[which(number_nas > 0 & number_nas < 3)])/nrow(d_transects2)
length(number_nas[which(number_nas > 2)])/nrow(d_transects2) # % of transects not sampled more than 2 years
1-0.23# % of transects sampled at least 8 years
number_nas
# Average number of years surveyed
mean(number_nas)
d_transects2
# Average number of years surveyed
years_sampled <- 9-number_nas
years_sampled
mean(years_sampled)
sd(years_sampled)
30-7
23-6
13/30
*100
